{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. 라이브러리"],"metadata":{"id":"8x7Lpxz7j0eb"}},{"cell_type":"code","source":["!pip install konlpy\n","!pip install networkx\n","!pip install apyori\n","!pip install pyLDAvis==2.1.2\n","!pip install wordcloud\n","!pip install twitter\n","!pip install gensim\n","!pip install openpyxl\n","!pip install xlrd"],"metadata":{"id":"yM2hr3RKj8C8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658298016895,"user_tz":-540,"elapsed":50322,"user":{"displayName":"전규보","userId":"10540878189074354135"}},"outputId":"dc7b79b5-0db0-4e74-bd29-2bb571344272"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n","\u001b[K     |████████████████████████████████| 453 kB 59.2 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.0 konlpy-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.6.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting apyori\n","  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n","Building wheels for collected packages: apyori\n","  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5974 sha256=4de3cd712faf4d7aabe3703e0db0d2b89aeb787987d3026865282cb61b01fb2c\n","  Stored in directory: /root/.cache/pip/wheels/cb/f6/e1/57973c631d27efd1a2f375bd6a83b2a616c4021f24aab84080\n","Successfully built apyori\n","Installing collected packages: apyori\n","Successfully installed apyori-1.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyLDAvis==2.1.2\n","  Downloading pyLDAvis-2.1.2.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.37.1)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.21.6)\n","Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.7.3)\n","Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.3.5)\n","Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.1.0)\n","Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.11.3)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.8.3)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (3.6.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.16.0)\n","Collecting funcy\n","  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.0.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.15.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis==2.1.2) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis==2.1.2) (3.0.9)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (57.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (21.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (8.13.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.4.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.11.0)\n","Building wheels for collected packages: pyLDAvis\n","  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97738 sha256=47b468191dea3f7da604483c6bada08d77b3a0b4b608a53c2dfd2d2064be952c\n","  Stored in directory: /root/.cache/pip/wheels/3b/fb/41/e32e5312da9f440d34c4eff0d2207b46dc9332a7b931ef1e89\n","Successfully built pyLDAvis\n","Installing collected packages: funcy, pyLDAvis\n","Successfully installed funcy-1.17 pyLDAvis-2.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting twitter\n","  Downloading twitter-1.19.3-py2.py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.1 MB/s \n","\u001b[?25hInstalling collected packages: twitter\n","Successfully installed twitter-1.19.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"]}]},{"cell_type":"code","source":["# 기본 \n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","import pandas as pd \n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","import matplotlib as mpl\n","%config InlineBackend.figure_format = 'retina'\n","import seaborn as sns\n","import re\n","import pickle \n","import openpyxl\n","from IPython.display import set_matplotlib_formats \n","\n","# 불용어\n","import nltk\n","nltk.download('stopwords')\n","\n","# konlpy\n","from konlpy.tag import Okt\n","okt = Okt()\n","from konlpy.tag import Twitter\n","twitter = Twitter()\n","\n","# counter\n","from collections import Counter\n","from sklearn.feature_extraction.text import CountVectorizer\n","vect = CountVectorizer()\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# wordcloud\n","from wordcloud import WordCloud \n","\n","# lda\n","from gensim import corpora, models\n","from gensim.models import CoherenceModel\n","import gensim\n","import pyLDAvis.gensim\n","import pyLDAvis\n","\n","# sna\n","import networkx as nx\n","from apyori import apriori"],"metadata":{"id":"xJNh4Ggej-Un","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658298021868,"user_tz":-540,"elapsed":4990,"user":{"displayName":"전규보","userId":"10540878189074354135"}},"outputId":"d3c6375a-4ad5-43dd-e01b-ea4e5fac45a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n","  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n","/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n","  from collections import Iterable\n"]}]},{"cell_type":"code","source":["# 운영체제별 한글 폰트 설정\n","if os.name == 'posix': # Mac 환경 폰트 설정\n","    plt.rc('font', family='AppleGothic')\n","elif os.name == 'nt': # Windows 환경 폰트 설정\n","    plt.rc('font', family='NanumGothic')\n","\n","plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n","\n","\n","# 글씨 선명하게 출력하는 설정\n","%config InlineBackend.figure_format = 'retina'"],"metadata":{"id":"V8cDFNuolD4S","colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"status":"error","timestamp":1658298022536,"user_tz":-540,"elapsed":678,"user":{"displayName":"전규보","userId":"10540878189074354135"}},"outputId":"3f303747-a3d9-446d-8f6d-6a91a4cf865d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f290f8440634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 운영체제별 한글 폰트 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'posix'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Mac 환경 폰트 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AppleGothic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Windows 환경 폰트 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NanumGothic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["# 이 셀까지 실행 후 런타임 초기화 요망\n","# 런타임 초기화 후 처음부터 재시작, 이 셀은 실행하지 않음\n","# 이 셀 스킵 후 다음 셀부터 시작\n","!sudo apt-get install -y fonts-NanumGothic\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"],"metadata":{"id":"qfKcGtyVlWpB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt -qq -y install fonts-nanum\n","import matplotlib.font_manager as fm\n","path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf' \n","font = fm.FontProperties(fname=path, size=9)\n","plt.rc('font', family='NanumGothic')\n","mpl.font_manager._rebuild()"],"metadata":{"id":"C_LQmlinlZFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. 불용어 리스트"],"metadata":{"id":"AYnZFp4nlpU2"}},{"cell_type":"code","source":["korean_stopwords_path = \"/korean_stopwords.txt\" # 기본 불용어 파일 \n","\n","with open(korean_stopwords_path, encoding='utf8') as f:\n","    stopwords = f.readlines()\n","stopwords = [x.strip() for x in stopwords]\n","\n","# 불용어 추가\n","other_stopwords = ['추가','불용어','리스트']\n","for stopword in other_stopwords:\n","    stopwords.append(stopword)"],"metadata":{"id":"8mQQH3Jhlq-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. 워드 클라우드"],"metadata":{"id":"Z12Ib5dyl5Ln"}},{"cell_type":"markdown","source":["## 2-1. 토큰화/불용어제거"],"metadata":{"id":"fhXiR02lnv1r"}},{"cell_type":"code","source":["def text_preprocessing(x):\n","  title_corpus = x['title'].tolist()  # 컬럼명 title\n","\n","  # 형태소 분석\n","  morphs = []\n","  for sentence in title_corpus:\n","    morphs.append(twitter.pos(str(sentence)))\n","  print(morphs)\n","  print('----------------------------------------------------------------------------------------------------')\n","  print()\n","  print()\n","\n","  # 품사 지정(명사)\n","  noun_adj_adv_list = []\n","  for sentence in morphs : \n","    for word, tag in sentence :\n","        if tag in ['Noun'] and (\"것\" not in word) and (\"내\" not in word)and (\"나\" not in word)and (\"수\"not in word) and(\"게\"not in word)and(\"말\"not in word): \n","            noun_adj_adv_list.append(word) \n","\n","  print(noun_adj_adv_list)\n","  print('----------------------------------------------------------------------------------------------------')\n","  print()\n","  print()\n","\n","  # 불용어 제거\n","  step1 = [x for x in noun_adj_adv_list if not x in stopwords] # N 입력 후 불용어 제거\n","  step2 = re.sub(r'[^ A-Za-z0-9가-힣+]', '', str(step1)) # N 입력 후 정규화\n","  shortword = re.compile(r'\\W*\\b\\w{1}\\b')\n","  step3 = shortword.sub('', step2) # N 입력 후 한글자 제거\n","  \n","  return step3 # 데이터에 따라 괜찮은 전처리 방식 return \n"],"metadata":{"id":"PPTrSP2Gl6CO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"ud2oXy7anP4J"}},{"cell_type":"markdown","source":["## 2-2. 워드클라우드 함수"],"metadata":{"id":"UYzlPGoBn4pf"}},{"cell_type":"code","source":["def wordcloud(x):\n","  # counter\n","  count = Counter(x)\n","  words = dict(count.most_common())\n","  print(words)\n","  print('----------------------------------------------------------------------------------------------------')\n","  print()\n","  print()\n","\n","  # 워드클라우드\n","  wordcloud = WordCloud(font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf', \n","                          background_color='white',colormap = \"Accent_r\", \n","                          width=1500, height=1000).generate_from_frequencies(words) \n","  plt.imshow(wordcloud) \n","  plt.axis('off') \n","  plt.show()\n","  print('----------------------------------------------------------------------------------------------------')\n","  print()\n","  print()\n"],"metadata":{"id":"5bqlgtT0n6vM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. LDA"],"metadata":{"id":"TS2fbmf2oL2X"}},{"cell_type":"markdown","source":["## 3-1. LDA용 전처리 함수"],"metadata":{"id":"OzZbeqV5oMts"}},{"cell_type":"code","source":["def preprocessing(x):\n","    title_corpus =\" \".join(map(str,x['title']))\n","\n","    df_noun = okt.nouns(title_corpus)\n","\n","    df_noun_x = [x for x in df_noun if not x in stopwords] # N 입력 후 불용어 제거\n","\n","    df_N_re = re.sub(r'[^ A-Za-z0-9가-힣+]', '', str(df_noun_x)) # N 입력 후 정규화\n","\n","    shortword = re.compile(r'\\W*\\b\\w{1}\\b')\n","    result = shortword.sub('', df_N_re) # N 입력 후 한글자 제거\n","\n","    return result"],"metadata":{"id":"pReOmHpWg4RU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 한글만\n","def text_cleaning(text):\n","    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') \n","    result = hangul.sub('', str(text))\n","    return result"],"metadata":{"id":"ENvK6X8_g4TZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 한글&영어\n","def text_cleaning(text):\n","    hangul = re.compile('[^A-Za-z0-9가-힣]') \n","    result = hangul.sub('', str(text))\n","    return result"],"metadata":{"id":"Xkj57ToPhPK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_nouns(x):\n","    nouns_tagger = Okt()\n","    nouns = nouns_tagger.nouns(x)\n","    # 한글자 키워드 제거\n","    nouns = [noun for noun in nouns if len(noun) > 1]\n","    # 불용어 제거\n","    nouns = [noun for noun in nouns if noun not in stopwords]\n","    return nouns"],"metadata":{"id":"ki6nQYo5g4VV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3-2. LDA"],"metadata":{"id":"G4aK0VZ_oZZj"}},{"cell_type":"code","source":["tfidfv = TfidfVectorizer().fit([result])\n","print(tfidfv.transform([result]).toarray())\n","qt_tfidf = tfidfv.vocabulary_\n","print(qt_tfidf)"],"metadata":{"id":"SY-WK2yog4ZT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id2word = corpora.Dictionary([result.split()]) # 정수인코딩과 빈도수 생성\n","corpus = [id2word.doc2bow(text) for text in [result.split()]] # 출현빈도가 작거나 자주 등장하는 단어는 제거\n","print(corpus)\n","NUM_TOPICS = 20 #20개의 토픽, k=20\n","ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=id2word, passes=15)\n","topics = ldamodel.print_topics(num_words=4)\n","for topic in topics:\n","    print(topic)\n","    pyLDAvis.enable_notebook()\n","vis = pyLDAvis.gensim.prepare(ldamodel, corpus, id2word)\n","#vis = pyLDAvis.gensim.prepare(ldamodel, corpus_tfidf, id2word)\n","pyLDAvis.display(vis)"],"metadata":{"id":"ojxrbX2qg4bQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. SNA"],"metadata":{"id":"7aYMgVnuoglo"}},{"cell_type":"code","source":["jp['ko_text'] = jp['title'].apply(lambda x : text_cleaning(x))\n","jp['nouns'] = jp['ko_text'].apply(lambda x: get_nouns(x))\n","print(jp)\n","transactions = jp['nouns'].tolist()\n","transactions = [transaction for transaction in transactions if transaction] # 공백 문자열 방지\n","print(transactions)\n","# 연관 분석 수행\n","results = list(apriori(transactions,\n","    min_support=0.06,\n","    min_confidence=0.05,\n","    min_lift=1.0,\n","    max_length=2))\n","print(results)\n","columns = ['source', 'target', 'support']\n","network_df = pd.DataFrame(columns=columns)\n","\n","# 규칙의 조건절을 source, 결과절을 target, 지지도를 support 라는 데이터 프레임의 피처로 변환\n","for result in results:\n","    if len(result.items) == 2:\n","        items = [x for x in result.items]\n","        row = [items[0], items[1], result.support]\n","        series = pd.Series(row, index=network_df.columns)\n","        network_df = network_df.append(series, ignore_index=True)\n","\n","network_df.head()"],"metadata":{"id":"wkNYuJwyg4e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = \"\".join(jp['ko_text'].tolist())\n","print(corpus)\n","# 명사 키워드 추출\n","nouns_tagger = Okt()\n","nouns = nouns_tagger.nouns(corpus)\n","# 불용어 제거 추가\n","df_noun_x = [x for x in nouns if not x in stopwords]\n","count = Counter(df_noun_x)\n","# 한글자 키워드 제거\n","remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n","\n","# 키워드와 키워드 빈도 점수를 ‘node’, ‘nodesize’ 라는 데이터 프레임의 피처로 생성\n","node_df = pd.DataFrame(remove_char_counter.items(), columns=['node', 'nodesize'])\n","node_df = node_df[node_df['nodesize'] >= 10] # 시각화의 편의를 위해 ‘nodesize’ 5 이하 제거\n","node_df.head()\n","plt.figure(figsize=(25,25))\n","\n","# networkx 그래프 객체 생성\n","G = nx.Graph()\n","\n","# node_df의 키워드 빈도수를 데이터로 하여, 네트워크 그래프의 ‘노드’ 역할을 하는 원 생성\n","for index, row in node_df.iterrows():\n","    G.add_node(row['node'], nodesize=row['nodesize'])\n","\n","# network_df의 연관 분석 데이터를 기반으로, 네트워크 그래프의 ‘관계’ 역할을 하는 선 생성\n","for index, row in network_df.iterrows():\n","    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n","\n","# 그래프 디자인과 관련된 파라미터 설정.\n","pos = nx.spring_layout(G, k=0.6, iterations=50)\n","sizes = [G.nodes[node]['nodesize']*25 for node in G]\n","nx.draw(G, pos=pos, node_size=sizes)\n","\n","nx.draw_networkx_labels(G, pos=pos, font_family=\"NanumGothic\", font_size=25)\n","\n","\n","\n","# 그래프 출력\n","ax = plt.gca()\n","plt.show()"],"metadata":{"id":"w_r9xgNVg4g-"},"execution_count":null,"outputs":[]}]}